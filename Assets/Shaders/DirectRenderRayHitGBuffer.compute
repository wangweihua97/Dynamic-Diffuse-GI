#pragma kernel CSMain
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
#include "GridHelpers.hlsl"
#define pi 3.1415926535

int probeSideLength;
float energyPreservation;
int2 baseColorMapSize;
int2 irradianceMapSize;

StructuredBuffer<IrradianceField> L;

Texture2DArray<float4> baseColorMaps;
Texture2D<float4> rayOrigin;

RWTexture2D<float3> posMap;
RWTexture2D<float3> normalMap;
RWTexture2D<float2> uvMap;
RWTexture2D<int> indexMap;

RWTexture2D<float3> rayHitColors;
Texture2D<float4> irradianceMeanMeanSquared;

SamplerState samplerirradianceMeanMeanSquared
{

    Filter   = MIN_MAG_MIP_LINEAR;

    AddressU = Clamp;

    AddressV = Clamp;

};

Texture2D<float4> irradianceMap;
SamplerState samplerirradianceMap
{

    Filter   = MIN_MAG_MIP_LINEAR;

    AddressU = Clamp;

    AddressV = Clamp;

};
TextureCube skyCubeMap;
SamplerState samplerskyCubeMap;

float3 BlinnPhongLighting(float3 posWS ,float3 normalWS ,int index ,float2 uv ,float3 v)
{
    float4 SHADOW_COORDS = TransformWorldToShadowCoord(posWS);
    Light light = GetMainLight(SHADOW_COORDS);
    
    half3 h = normalize(light.direction + v);
    
    half nl = max(0.0,dot(light.direction ,normalWS));
    half nh = max(0.0,dot(h ,normalWS));
    
    half atten = light.shadowAttenuation;
    int2 iuv = int2(baseColorMapSize * uv);
    //float3 baseCorlor = baseColorMaps[uint3(iuv.x ,iuv.y ,index)].xyz;
    float3 baseCorlor = baseColorMaps[uint3(iuv.x ,iuv.y ,0)].xyz;
    half3 diffuse = nl * baseCorlor* light.color;
    half3 specular = atten * light.color * pow(nh ,16);
    return diffuse + specular;
}


[numthreads(8,8,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
    // Screen-space point being shaded
    uint2 C = id.xy;

    float3 wsN = normalMap[C].xyz;
    float3 wsPosition = posMap[C].xyz;
    int hitIndex = indexMap[C].x;
    float2 hitUv = uvMap[C].xy;
    
    if (dot(wsN, wsN) < 0.01) {
        rayHitColors[C] = float3(0,0,0);
        return;
    }
    
    
    // View vector
    //float3 w_o = normalize(rayOrigin[C].xyz - wsPosition);
    float3 w_o = normalize(wsPosition - rayOrigin[C].xyz);
    if (hitIndex < 0) {
        rayHitColors[C] = skyCubeMap.SampleLevel(samplerskyCubeMap, w_o, 0);
        return;
    }
    // Glossy coefficient in BSDF (this code unpacks
    // G3D::UniversalBSDF's encoding)
    /*float4  F0 = texelFetch(gbuffer_GLOSSY_buffer, C, 0);

    float glossyExponent = smoothnessToBlinnPhongExponent(F0.a);

    float cos_o = dot(wsN, w_o);

    float3 w_mi = normalize(wsN * (2.0 * cos_o) - w_o);

    E_glossyIndirect = computeGlossyEnvironmentMapLighting(w_mi, (F0.a == 1.0), glossyExponent, false);*/
    
    float3 blinnPhong = BlinnPhongLighting(wsPosition ,wsN ,hitIndex ,hitUv ,w_o);

    int3 gridCoord = baseGridCoord(L[0], wsPosition);
    float3 baseProbePos = gridCoordToPosition(L[0], gridCoord);
    Irradiance3 sumIrradiance = Irradiance3(0,0,0);
    float sumWeight = 0.0;

    // alpha is how far from the floor(currentVertex) position. on [0, 1] for each axis.
    float3 alpha = clamp((wsPosition - baseProbePos) / L[0].probeStep, float3(0,0,0), float3(1,1,1));

    // Iterate over adjacent probe cage
    for (int i = 0; i < 8; ++i) {
        // Compute the offset grid coord and clamp to the probe grid boundary
        // Offset = 0 or 1 along each axis
        GridCoord  offset = int3(i, i >> 1, i >> 2) & int3(1,1,1);
        GridCoord  probeGridCoord = clamp(gridCoord + offset, GridCoord(0,0,0), GridCoord(L[0].probeCounts - GridCoord(1,1,1)));
        ProbeIndex p = gridCoordToProbeIndex(L[0], probeGridCoord);

        // Make cosine falloff in tangent plane with respect to the angle from the surface to the probe so that we never
        // test a probe that is *behind* the surface.
        // It doesn't have to be cosine, but that is efficient to compute and we must clip to the tangent plane.
        float3 probePos = gridCoordToPosition(L[0], probeGridCoord);

        // Bias the position at which visibility is computed; this
        // avoids performing a shadow test *at* a surface, which is a
        // dangerous location because that is exactly the line between
        // shadowed and unshadowed. If the normal bias is too small,
        // there will be light and dark leaks. If it is too large,
        // then samples can pass through thin occluders to the other
        // side (this can only happen if there are MULTIPLE occluders
        // near each other, a wall surface won't pass through itself.)
        float3 probeToPoint = wsPosition - probePos + (wsN + 3.0 * w_o) * L[0].normalBias;
        float3 dir = normalize(-probeToPoint);

        // Compute the trilinear weights based on the grid cell vertex to smoothly
        // transition between probes. Avoid ever going entirely to zero because that
        // will cause problems at the border probes. This isn't really a lerp. 
        // We're using 1-a when offset = 0 and a when offset = 1.
        float3 trilinear = lerp(1.0 - alpha, alpha, offset);
        float weight = 1.0;

        // Clamp all of the multiplies. We can't let the weight go to zero because then it would be 
        // possible for *all* weights to be equally low and get normalized
        // up to 1/n. We want to distinguish between weights that are 
        // low because of different factors.

        // Smooth backface test
        {
            // Computed without the biasing applied to the "dir" variable. 
            // This test can cause reflection-map looking errors in the image
            // (stuff looks shiny) if the transition is poor.
            float3 trueDirectionToProbe = normalize(probePos - wsPosition);

            // The naive soft backface weight would ignore a probe when
            // it is behind the surface. That's good for walls. But for small details inside of a
            // room, the normals on the details might rule out all of the probes that have mutual
            // visibility to the point. So, we instead use a "wrap shading" test below inspired by
            // NPR work.
            // weight *= max(0.0001, dot(trueDirectionToProbe, wsN));

            // The small offset at the end reduces the "going to zero" impact
            // where this is really close to exactly opposite
            weight *= square(max(0.0001, (dot(trueDirectionToProbe, wsN) + 1.0) * 0.5)) + 0.2;
        }
        
        // Moment visibility test
        {
            float2 texCoord = textureCoordFromDirection(-dir,
                p,
                L[0].depthTextureWidth,
                L[0].depthTextureHeight,
                L[0].depthProbeSideLength);

            float distToProbe = length(probeToPoint);
            //int2 itexCoord = int2(irradianceMapSize * texCoord);
            //float2 temp = irradianceMeanMeanSquared[itexCoord].xy;
            float2 temp = irradianceMeanMeanSquared.SampleLevel(samplerirradianceMeanMeanSquared, texCoord ,0).rg;
            float mean = temp.x;
            float variance = abs(square(temp.x) - temp.y);

            // http://www.punkuser.net/vsm/vsm_paper.pdf; equation 5
            // Need the max in the denominator because biasing can cause a negative displacement
            float chebyshevWeight = variance / (variance + square(max(distToProbe - mean, 0.0)));
                
            // Increase contrast in the weight 
            chebyshevWeight = max(pow3(chebyshevWeight), 0.0);

            weight *= (distToProbe <= mean) ? 1.0 : chebyshevWeight;
        }

        // Avoid zero weight
        weight = max(0.000001, weight);
                 
        float3 irradianceDir = wsN;

        float2 texCoord = textureCoordFromDirection(normalize(irradianceDir),
            p,
            L[0].irradianceTextureWidth,
            L[0].irradianceTextureHeight,
            L[0].irradianceProbeSideLength);
        //int2 itexCoord = int2(irradianceMapSize * texCoord);
        //Irradiance3 probeIrradiance = texture(L[0].irradianceProbeGridbuffer, texCoord).rgb;
        //Irradiance3 probeIrradiance = irradianceMap[itexCoord].rgb;
        
        Irradiance3 probeIrradiance = irradianceMap.SampleLevel(samplerirradianceMap, texCoord ,0).rgb;
        

        // A tiny bit of light is really visible due to log perception, so
        // crush tiny weights but keep the curve continuous. This must be done
        // before the trilinear weights, because those should be preserved.
        const float crushThreshold = 0.2;
        if (weight < crushThreshold) {
            weight *= weight * weight * (1.0 / square(crushThreshold)); 
        }

        // Trilinear weights
        weight *= trilinear.x * trilinear.y * trilinear.z;

        // Weight in a more-perceptual brightness space instead of radiance space.
        // This softens the transitions between probes with respect to translation.
        // It makes little difference most of the time, but when there are radical transitions
        // between probes this helps soften the ramp.
#       if LINEAR_BLENDING == 0
            probeIrradiance = sqrt(probeIrradiance);
#       endif
        
        sumIrradiance += weight * probeIrradiance;
        sumWeight += weight;
    }

    Irradiance3 netIrradiance = sumIrradiance / sumWeight;

    // Go back to linear irradiance
#   if LINEAR_BLENDING == 0
        netIrradiance = square(netIrradiance);
#   endif
    netIrradiance *= energyPreservation;

    rayHitColors[C] = 0.5 * pi * netIrradiance + blinnPhong;
}
